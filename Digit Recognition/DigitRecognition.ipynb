{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DigitRecognition.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"XIyJN-sHrdNy","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GCqFcgihrvmY","colab_type":"code","outputId":"af14d24b-c640-4809-c1cd-ce2825b3f923","executionInfo":{"status":"ok","timestamp":1578458847378,"user_tz":-330,"elapsed":27526,"user":{"displayName":"Anirudh Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCdXxtVr1wLgATuZM1iQDnE6Hw_mvTb2TIVWUeUNA=s64","userId":"08894094281719011062"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ys7AIItcrv7v","colab_type":"code","colab":{}},"source":["\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W-rqy7cCsNLg","colab_type":"code","outputId":"6238d251-3f21-4590-e1aa-63b0236ce689","executionInfo":{"status":"ok","timestamp":1577731164491,"user_tz":-330,"elapsed":102932,"user":{"displayName":"Anirudh Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCdXxtVr1wLgATuZM1iQDnE6Hw_mvTb2TIVWUeUNA=s64","userId":"08894094281719011062"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":[""],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting keras-tuner\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/93/5db8ac61f6547ce94b534a1cf614961a6e302559f0cdd1b37248052c9761/keras_tuner-1.0.0-py2.py3-none-any.whl (88kB)\n","\r\u001b[K     |███▊                            | 10kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 30kB 3.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 40kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 51kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 61kB 3.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 71kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 81kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 3.6MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.28.1)\n","Collecting tensorflow>=2.0.0-beta1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/44/4e8cc8c84cf235628ee919ba97ee029f2d080fa3573e26fe726973d004b4/tensorflow-2.1.0rc2-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n","\u001b[K     |████████████████████████████████| 421.8MB 38kB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.21.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.6)\n","Collecting terminaltables\n","  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n","Collecting colorama\n","  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.17.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (5.4.8)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.21.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.3.3)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (0.8.1)\n","Collecting tensorboard<2.2.0,>=2.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 37.0MB/s \n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (3.1.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (3.10.0)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (0.2.2)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (1.11.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (1.12.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (1.1.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (0.8.1)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (1.0.8)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (1.15.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (0.33.6)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (0.1.8)\n","Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n","\u001b[K     |████████████████████████████████| 450kB 38.8MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (1.1.0)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2019.11.28)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.14.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (42.0.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (3.1.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (0.16.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (0.4.1)\n","Collecting google-auth<2,>=1.6.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/f8/84b5771faec3eba9fe0c91c8c5896364a8ba08852c0dea5ad2025026dd95/google_auth-1.10.0-py2.py3-none-any.whl (76kB)\n","\u001b[K     |████████████████████████████████| 81kB 10.9MB/s \n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow>=2.0.0-beta1->keras-tuner) (2.8.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (1.3.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (4.0.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (0.2.7)\n","Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (4.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (0.4.8)\n","Building wheels for collected packages: terminaltables\n","  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15354 sha256=dabde1ff485b6fb8c95918709f98e9b8418bc0f8cc016c4d692f7fca15820023\n","  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n","Successfully built terminaltables\n","\u001b[31mERROR: tensorflow 2.1.0rc2 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.3.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorboard 2.1.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.10.0 which is incompatible.\u001b[0m\n","Installing collected packages: google-auth, tensorboard, tensorflow-estimator, tensorflow, terminaltables, colorama, keras-tuner\n","  Found existing installation: google-auth 1.4.2\n","    Uninstalling google-auth-1.4.2:\n","      Successfully uninstalled google-auth-1.4.2\n","  Found existing installation: tensorboard 1.15.0\n","    Uninstalling tensorboard-1.15.0:\n","      Successfully uninstalled tensorboard-1.15.0\n","  Found existing installation: tensorflow-estimator 1.15.1\n","    Uninstalling tensorflow-estimator-1.15.1:\n","      Successfully uninstalled tensorflow-estimator-1.15.1\n","  Found existing installation: tensorflow 1.15.0\n","    Uninstalling tensorflow-1.15.0:\n","      Successfully uninstalled tensorflow-1.15.0\n","Successfully installed colorama-0.4.3 google-auth-1.10.0 keras-tuner-1.0.0 tensorboard-2.1.0 tensorflow-2.1.0rc2 tensorflow-estimator-2.1.0 terminaltables-3.1.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google","tensorboard","tensorflow","tensorflow_core","tensorflow_estimator"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Jk6hoabisQJl","colab_type":"code","colab":{}},"source":["\n","#X=pd.read_table('/content/drive/My Drive/Colab Notebooks/DigitRecognitionMnist/t10k-images.idx3-ubyte',encoding='utf-8',error_bad_lines=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X0R_-WAwuyFA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ubpJNMJw5J1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ab8dr0L9yEFq","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eM4KXUDCzCJo","colab_type":"code","colab":{}},"source":["\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GqjDRnx3zLHK","colab_type":"code","colab":{}},"source":["\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OTI_No7YByuH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1morOsHFB8c_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iU0cLjrSCKFR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6c1ovd-YI8jH","colab_type":"code","colab":{}},"source":["pip install keras-tuner\n","import pandas as pd\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras\n","import struct as st\n","\n","\n","filename = {'images' : '/content/drive/My Drive/Colab Notebooks/DigitRecognitionMnist/train-images.idx3-ubyte' ,'labels' : '/content/drive/My Drive/Colab Notebooks/DigitRecognitionMnist/train-labels.idx1-ubyte'}\n","\n","train_imagesfile = open(filename['images'],'rb')\n","train_labelsfile=  open(filename['labels'],'rb')\n","\n","\n","train_imagesfile.seek(0)\n","magic = st.unpack('>4B',train_imagesfile.read(4))\n","train_labelsfile.seek(0)\n","magic1 = st.unpack('>4B',train_labelsfile.read(4))\n","\n","\n","nImg = st.unpack('>I',train_imagesfile.read(4))[0] #num of images\n","nR = st.unpack('>I',train_imagesfile.read(4))[0] #num of rows\n","nC = st.unpack('>I',train_imagesfile.read(4))[0] #num of column\n","\n","\n","cols= st.unpack('>I',train_labelsfile.read(4))[0] #num of Images\n","\n","\n","nBytesTotal1 = cols*1 #since each pixel data is 1 byte\n","y=  np.asarray(st.unpack('>'+'B'*nBytesTotal1,train_labelsfile.read(nBytesTotal1))).reshape((cols,1))\n","\n","nBytesTotal = nImg*nR*nC*1 #since each pixel data is 1 byte\n","X= 255 - np.asarray(st.unpack('>'+'B'*nBytesTotal,train_imagesfile.read(nBytesTotal))).reshape((nImg,nR,nC))\n","\n","#standardizing the input values\n","X=X/255\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=(1/12))\n","\n","\n","X_train=X_train.reshape(X_train.shape[0],1,X_train.shape[1],X_train.shape[2])\n","X_test=X_test.reshape(X_test.shape[0],1,X_test.shape[1],X_test.shape[2])\n","\n","from tensorflow import keras\n","from keras.layers import Dense,Dropout\n","from keras.layers import ReLU,LeakyReLU,PReLU,ELU\n","from keras.models import Sequential \n","\n","\n","\n","def bulid_model(hp):\n","  model=keras.Sequential([\n","                          keras.layers.Conv2D(filters=hp.Int('Conv_1',max_value=128,min_value=16,step=16),\n","                                              kernel_size=hp.Choice('kernel1',values=[3,5]),\n","                                              strides=(1,1),\n","                                              activation='relu',\n","                                              kernel_intializer='he_uniform',\n","                                              input_shape=(1,X_train.shape[2],X_train.shape[3])),\n","                          keras.layers.MaxPool2D(pool_size=(2,2),padding='same'),\n","                          keras.layers.Conv2D(filters=hp.Int('Conv_2',max_value=256,min_value=32,step=32),\n","                                              kernel_size=hp.Choice('kernel2',values=[3,5]),\n","                                              strides=(1,1),\n","                                              activation='relu',\n","                                              kernel_intializer='he_uniform'),\n","                                              \n","                          keras.layers.MaxPool2D(pool_size=(2,2),padding='same'),\n","                          keras.layers.Conv2D(filters=hp.Int('Conv_3',max_value=1024,min_value=256,step=16),\n","                                              kernel_size=hp.Choice('kernel3',values=[3,5]),\n","                                              strides=(1,1),\n","                                              activation='relu',\n","                                              kernel_intializer='he_uniform'),\n","                                              \n","                          keras.layers.Conv2D(filters=hp.Int('Conv_4',max_value=1024,min_value=256,step=64),\n","                                              kernel_size=hp.Choice('kernel4',values=[3,5]),\n","                                              strides=(1,1),\n","                                              activation='relu',\n","                                              kernel_intializer='he_uniform'),\n","                                              \n","                          keras.layers.MaxPool2D(pool_size=(2,2),padding='same'),\n","                          keras.layers.Dense(units=hp.Int('dense_1',max_value=1024,min_value=16,step=16),\n","                                             activation='relu',\n","                                             kernel_intializer='he_uniform'),\n","                          keras.layers.Dense(units=hp.Int('dense_2',max_value=1024,min_value=16,step=16),\n","                                             activation='relu',\n","                                             kernel_intializer='he_uniform'),\n","                          keras.layers.Dense(units=10,\n","                                             activation='softmax',\n","                                             kernel_intializer='glorot_uniform')\n","  \n","  \n","  ])\n","\n","  model.compile(loss='sparse_categorical_crossentropy',optimizer=keras.optimizers.Adam(hp.Choice('learningrate',values=[1e-1,1e-2,1e-3])),metrics=['accuracy'])\n","  return model\n","\n","\n","\n","from kerastuner import RandomSearch\n","import kerastuner.engine.hyperparameters as hp  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fgb_ltW4Jy3L","colab_type":"code","outputId":"3ad4beec-6ae3-4786-a71d-1dc7920f0012","executionInfo":{"status":"error","timestamp":1577733272657,"user_tz":-330,"elapsed":1978,"user":{"displayName":"Anirudh Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCdXxtVr1wLgATuZM1iQDnE6Hw_mvTb2TIVWUeUNA=s64","userId":"08894094281719011062"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":[""],"execution_count":0,"outputs":[{"output_type":"stream","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-49-a44a783bb2ce>\", line 1, in <module>\n","    from kerastuner import RandomSearch\n","  File \"/usr/local/lib/python3.6/dist-packages/kerastuner/__init__.py\", line 19, in <module>\n","    from kerastuner import applications\n","  File \"/usr/local/lib/python3.6/dist-packages/kerastuner/applications/__init__.py\", line 17, in <module>\n","    from .resnet import HyperResNet\n","  File \"/usr/local/lib/python3.6/dist-packages/kerastuner/applications/resnet.py\", line 19, in <module>\n","    from tensorflow.keras import layers\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 50, in __getattr__\n","    module = self._load()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 44, in _load\n","    module = _importlib.import_module(self.__name__)\n","  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n","    return _bootstrap._gcd_import(name[level:], package, level)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/api/_v1/keras/__init__.py\", line 16, in <module>\n","    from . import backend\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/api/_v1/keras/backend/__init__.py\", line 11, in <module>\n","    from tensorflow.python.framework.ops import name_scope_v1 as name_scope\n","ImportError: cannot import name 'name_scope_v1'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n","    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n","  File \"/usr/lib/python3.6/inspect.py\", line 733, in getmodule\n","    if ismodule(module) and hasattr(module, '__file__'):\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 50, in __getattr__\n","    module = self._load()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 44, in _load\n","    module = _importlib.import_module(self.__name__)\n","  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n","    return _bootstrap._gcd_import(name[level:], package, level)\n","  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n","  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n","  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n","  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/api/_v1/keras/__init__.py\", line 16, in <module>\n","    from . import backend\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/api/_v1/keras/backend/__init__.py\", line 11, in <module>\n","    from tensorflow.python.framework.ops import name_scope_v1 as name_scope\n","ImportError: cannot import name 'name_scope_v1'\n"],"name":"stdout"},{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"aih5j44JNRFK","colab_type":"code","colab":{}},"source":["'''\n","import pandas as pd\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras\n","import struct as st\n","\n","\n","filename = {'images' : '/content/drive/My Drive/Colab Notebooks/DigitRecognitionMnist/train-images.idx3-ubyte' ,'labels' : '/content/drive/My Drive/Colab Notebooks/DigitRecognitionMnist/train-labels.idx1-ubyte'}\n","\n","train_imagesfile = open(filename['images'],'rb')\n","train_labelsfile=  open(filename['labels'],'rb')\n","\n","\n","train_imagesfile.seek(0)\n","magic = st.unpack('>4B',train_imagesfile.read(4))\n","train_labelsfile.seek(0)\n","magic1 = st.unpack('>4B',train_labelsfile.read(4))\n","\n","\n","nImg = st.unpack('>I',train_imagesfile.read(4))[0] #num of images\n","nR = st.unpack('>I',train_imagesfile.read(4))[0] #num of rows\n","nC = st.unpack('>I',train_imagesfile.read(4))[0] #num of column\n","\n","\n","cols= st.unpack('>I',train_labelsfile.read(4))[0] #num of Images\n","\n","\n","nBytesTotal1 = cols*1 #since each pixel data is 1 byte\n","y=  np.asarray(st.unpack('>'+'B'*nBytesTotal1,train_labelsfile.read(nBytesTotal1))).reshape((cols,1))\n","\n","nBytesTotal = nImg*nR*nC*1 #since each pixel data is 1 byte\n","X= 255 - np.asarray(st.unpack('>'+'B'*nBytesTotal,train_imagesfile.read(nBytesTotal))).reshape((nImg,nR,nC))\n","\n","#standardizing the input values\n","X=X/255\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=(1/12))\n","\n","\n","arr = np.array(y_train)\n","data=arr.flatten()\n","df = pd.DataFrame()\n","df['label'] = (data)\n","y_train=df['label']\n","\n","\n","X_train=X_train.reshape(X_train.shape[0],1,X_train.shape[1],X_train.shape[2])\n","X_test=X_test.reshape(X_test.shape[0],1,X_test.shape[1],X_test.shape[2])\n","\n","from tensorflow import keras\n","from keras.layers import Dense,Dropout\n","from keras.layers import ReLU,LeakyReLU,PReLU,ELU\n","from keras.models import Sequential \n","\n","\n","\n","def bulid_model(hp):\n","  model=keras.Sequential([\n","                          keras.layers.Conv2D(filters=64,\n","                                              kernel_size=(3,3),\n","                                              strides=(1,1),\n","                                              activation='relu',\n","                                              kernel_initializer='he_uniform',\n","                                              input_shape=(1,28,28),\n","                                              data_format='channels_first'),\n","                          keras.layers.MaxPool2D(pool_size=(2,2),padding='same'),\n","                          keras.layers.Conv2D(filters=128,\n","                                              kernel_size=(3,3),\n","                                              strides=(1,1),\n","                                              activation='relu',\n","                                              kernel_initializer='he_uniform',\n","                                              data_format='channels_first'),\n","                                              \n","                          keras.layers.MaxPool2D(pool_size=(2,2),padding='same'),\n","                          keras.layers.Conv2D(filters=256,\n","                                              kernel_size=(3,3),\n","                                              strides=(1,1),\n","                                              activation='relu',\n","                                              kernel_initializer='he_uniform',\n","                                               data_format='channels_first'),\n","                                              \n","                          keras.layers.Conv2D(filters=256,\n","                                              kernel_size=(3,3),\n","                                              strides=(1,1),\n","                                              activation='relu',\n","                                              kernel_initializer='he_uniform',\n","                                              data_format='channels_first'),\n","                                              \n","                          keras.layers.MaxPool2D(pool_size=(2,2),padding='same'),\n","                          keras.layers.Flatten(),\n","                          keras.layers.Dense(units=1024,\n","                                             activation='relu',\n","                                             input_dim=256,\n","                                             kernel_initializer='he_uniform'),\n","                          keras.layers.Dense(units=1024,\n","                                             input_dim=1024,\n","                                             activation='relu',\n","                                             kernel_initializer='he_uniform'),\n","                          keras.layers.Dense(units=10,\n","                                             input_dim=1024,\n","                                             activation='softmax',\n","                                             kernel_initializer='glorot_uniform')\n","  \n","  \n","  ])\n","\n","  model.compile(loss='sparse_categorical_crossentropy',optimizer=keras.optimizers.Adam(hp.Choice('learningrate',values=[1e-1,1e-2,1e-3])),metrics=['accuracy'])\n","  model.summary()\n","  return model\n","\n","\n","\n","from kerastuner import RandomSearch\n","import kerastuner.engine.hyperparameters as hp  \n","\n","tuner_search=RandomSearch(bulid_model,\n","                          objective='val_accuracy',\n","                          max_trials=5\n","                          )\n","\n","tuner_search.search(X_train,y_train,epochs=3,validation_split=0.1)\n","model=tuner_search.get_best_models(num_models=1)[0]\n","model.fit(X_train,y_train,epochs=10,initial_epoch=3,validation_split=0.1)\n","\n","\n","y_pred=model.predict_classes(X_test)\n","from sklearn.metrics import accuracy_score,confusion_matrix\n","score=accuracy_score(y_pred,y_test)\n","cm=confusion_matrix(y_pred,y_test)\n","\n","\n","#loadig my own handwriiten imagr from the drive\n","from keras.preprocessing.image import ImageDataGenerator,array_to_img,img_to_array,load_img\n","img=load_img('/content/drive/My Drive/Colab Notebooks/DigitRecognitionMnist/IMG_20191231_111452.jpg',target_size=(28, 28))\n","\n","img = np.expand_dims(img, axis=0)\n","img = img.reshape(img.shape[1:])\n","b=[0.3,0.59,0.11]\n","img=np.dot(img,b)\n","img=img.reshape(1,1,img.shape[0],img.shape[1])\n","img=img/255.0\n","\n","y_got=model.predict_classes(img)\n","\n","\n","\n","#creating more images for better training\n","img=load_img('/content/drive/My Drive/Colab Notebooks/DigitRecognitionMnist/IMG_20191231_111452.jpg',target_size=(28, 28))\n","x=img_to_array(img)\n","x=x.reshape((1,)+x.shape)\n","i=0\n","for batch in datagen.flow(x,batch_size=1,save_to_dir='/content/drive/My Drive/Colab Notebooks/DigitRecognitionMnist',save_format='jpeg'):\n","  i=i+1\n","  if(i>20):\n","    break\n","    '''\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dOhgV-vEeeGx","colab_type":"code","outputId":"47563543-553a-49d1-eecf-8646d98827bb","executionInfo":{"status":"error","timestamp":1578463692822,"user_tz":-330,"elapsed":13179,"user":{"displayName":"Anirudh Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCdXxtVr1wLgATuZM1iQDnE6Hw_mvTb2TIVWUeUNA=s64","userId":"08894094281719011062"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install keras-tuner\n","import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","from tensorflow import keras\n","\n","X_test=pd.read_csv('/content/drive/My Drive/Colab Notebooks/DigitRecognitionMnist/test.csv')\n","#X_val=pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/miteshsir/val.csv\")\n","X_train=pd.read_csv('/content/drive/My Drive/Colab Notebooks/DigitRecognitionMnist/train.csv')\n","\n","from sklearn.model_selection import train_test_split\n","X_train,X_val=train_test_split(X_train)\n","\n","\n","\n","y_train=X_train['label']\n","y_val=X_val['label']\n","\n","\n","#X_test=X_test.drop(['id'],axis=1)\n","X_train=X_train.drop(['label'],axis=1)\n","X_val=X_val.drop(['label'],axis=1)\n","\n","\n","X_train=X_train.to_numpy(dtype=int)\n","X_test=X_test.to_numpy(dtype=int)\n","X_val=X_val.to_numpy(dtype=int)\n","\n","\n","\n","mtest=X_test.shape[0]\n","n=X_test.shape[1]\n","mtrain=X_train.shape[0]\n","mval=X_val.shape[0]\n","import math\n","n_test=math.sqrt(n)\n","\n","\n","'''from sklearn.preprocessing import StandardScaler\n","sc=StandardScaler()\n","X_train=sc.fit_transform(X_train)\n","X_test=sc.fit_transform(X_test)\n","X_val=sc.fit_transform(X_val)'''\n","\n","X_train=X_train/255\n","X_test=X_test/255\n","X_val=X_val/255\n","\n","X_train=X_train.reshape((int(mtrain),1,int(n_test),int(n_test)))\n","X_test=X_test.reshape((int(mtest),1,int(n_test),int(n_test)))\n","X_val=X_val.reshape((int(mval),1,int(n_test),int(n_test)))\n","#X_train=np.vstack((X_train,X_val))\n","\n","\n","from keras.models import Sequential\n","from keras.layers import Conv2D,Dense,Flatten,MaxPool2D,Dropout\n","from keras.layers import PReLU,LeakyReLU,ELU\n","from keras import backend as K\n","\n","K.common.image_dim_ordering()\n","K.common.set_image_dim_ordering(dim_ordering='th')\n","\n","def build_model(hp):\n","  model=keras.Sequential([\n","                          keras.layers.Conv2D(filters=64,\n","                                              #kernel_initializer='he_uniform',\n","                                              strides=(1,1),\n","                                              activation='relu',\n","                                              input_shape=(1,int(n_test),int(n_test)),\n","                                              kernel_size=(3,3),\n","                                              data_format='channels_first'\n","                                              ),\n","                          keras.layers.MaxPool2D(pool_size=(2,2),padding='same'),\n","                          keras.layers.Dropout(0.2),\n","\n","                          keras.layers.Conv2D(kernel_size=(3,3),\n","                                              kernel_initializer='he_uniform',\n","                                              strides=(1,1),\n","                                              activation='relu',\n","                                              data_format='channels_first',\n","                                              filters=128\n","                                              ),\n","                          keras.layers.MaxPool2D(pool_size=(2,2),padding='same'),\n","                          keras.layers.Dropout(0.2),\n","                          \n","\n","                          keras.layers.Conv2D(filters=256,\n","                                              kernel_size=(3,3),\n","                                              kernel_initializer='he_uniform',\n","                                              strides=(1,1),\n","                                              activation='relu',\n","                                              data_format='channels_first'\n","                                              ),\n","                          keras.layers.Conv2D(filters=256,\n","                                              kernel_size=(3,3),\n","                                              kernel_initializer='he_uniform',\n","                                              strides=(1,1),\n","                                              activation='relu',\n","                                              data_format='channels_first'\n","                                              ),\n","                          keras.layers.MaxPool2D(pool_size=(2,2),padding='same'),\n","                          keras.layers.Flatten(),\n","                          keras.layers.Dense(units=1024,input_dim=256,activation='relu',kernel_initializer='he_uniform'),\n","                          keras.layers.Dense(units=4096,input_dim=1024,activation='relu',kernel_initializer='he_uniform'),\n","                          keras.layers.Dense(units=4096,input_dim=4096,activation='relu',kernel_initializer='he_uniform'),\n","\n","                          keras.layers.Dense(units=10,input_dim=1024,activation='softmax',kernel_initializer='glorot_uniform')\n","\n","                                                  \n","  ])\n","\n","  model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learningrate',values=[1e-2,1e-3,1e-1,1e-4])),\n","                loss=\"sparse_categorical_crossentropy\",\n","                metrics=['accuracy'])\n","  model.summary()\n","  return model\n","\n","from kerastuner import RandomSearch\n","import kerastuner.engine.hyperparameters as Hyperparametrs\n","\n","\n","tuner_search=RandomSearch(build_model,\n","                          objective='acc',\n","                          max_trials=5,\n","                          directory=\"save_dir\"\n","                          )\n","\n","tuner_search.search(X_train,y_train,epochs=3)\n","\n","model=tuner_search.get_best_models(num_models=1)[0]\n","model.fit(X_train,y_train,epochs=20,initial_epoch=3,batch_size=15,validation_split=0.1)\n","\n","y_pred1=model.predict_classes(X_val)\n","y_test=model.predict_classes(X_test)\n","\n","from sklearn.metrics import accuracy_score\n","score1=accuracy_score(y_pred1,y_val)\n","\n","from sklearn.metrics import confusion_matrix\n","cm=confusion_matrix(y_pred1,y_val)\n","\n","\n","test_id=[]\n","for i in range(mtest):\n","  test_id.append(i+1)\n","\n","test_id=np.asarray(test_id)\n","test_id=test_id.reshape(28000,)\n","\n","dataset = pd.DataFrame({'label': y_test})\n","test_id=pd.DataFrame({'Imageid':test_id})\n","submission = pd.concat([test_id, dataset], axis=1)\n","submission.to_csv('submission.csv')\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras-tuner in /usr/local/lib/python3.6/dist-packages (1.0.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.21.3)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.17.4)\n","Requirement already satisfied: terminaltables in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (3.1.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.21.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.3.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.28.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.14.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2019.11.28)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.8)\n","INFO:tensorflow:Reloading Oracle from existing project save_dir/untitled_project/oracle.json\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 64, 26, 26)        640       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 32, 13, 26)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 32, 13, 26)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 128, 11, 24)       36992     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 64, 6, 24)         0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 64, 6, 24)         0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 256, 4, 22)        147712    \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 256, 2, 20)        590080    \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 128, 1, 20)        0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 2560)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 1024)              2622464   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4096)              4198400   \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 4096)              16781312  \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                40970     \n","=================================================================\n","Total params: 24,418,570\n","Trainable params: 24,418,570\n","Non-trainable params: 0\n","_________________________________________________________________\n","INFO:tensorflow:Reloading Tuner from save_dir/untitled_project/tuner0.json\n","INFO:tensorflow:Oracle triggered exit\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 64, 26, 26)        640       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 32, 13, 26)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 32, 13, 26)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 128, 11, 24)       36992     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 64, 6, 24)         0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 64, 6, 24)         0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 256, 4, 22)        147712    \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 256, 2, 20)        590080    \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 128, 1, 20)        0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 2560)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 1024)              2622464   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4096)              4198400   \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 4096)              16781312  \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                40970     \n","=================================================================\n","Total params: 24,418,570\n","Trainable params: 24,418,570\n","Non-trainable params: 0\n","_________________________________________________________________\n","WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n","\n","Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f62f014c6d8> and <tensorflow.python.keras.layers.core.Dropout object at 0x7f62f014c828>).\n","WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n","\n","Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f62f014ccc0> and <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f62f014cb70>).\n","WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n","\n","Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6303ddbc88> and <tensorflow.python.keras.layers.core.Dropout object at 0x7f62f014c2e8>).\n","WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n","\n","Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7f6301d68a58> and <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6303ddb898>).\n","WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n","\n","Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7f6301d68da0> and <tensorflow.python.keras.layers.core.Flatten object at 0x7f62a406af60>).\n","WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n","\n","Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7f62a46a6710> and <tensorflow.python.keras.layers.core.Dense object at 0x7f6301d68a58>).\n","Train on 28350 samples, validate on 3150 samples\n","Epoch 4/20\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-0435ae083e62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuner_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0my_pred1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: Matrix size-incompatible: In[0]: [15,10], In[1]: [4096,10]\n\t [[{{node dense_3/MatMul}}]]\n\t [[metrics/acc/Identity/_231]]\n  (1) Invalid argument: Matrix size-incompatible: In[0]: [15,10], In[1]: [4096,10]\n\t [[{{node dense_3/MatMul}}]]\n0 successful operations.\n0 derived errors ignored."]}]},{"cell_type":"code","metadata":{"id":"FWJ8qxvmgtdf","colab_type":"code","outputId":"e0ee1df3-988b-4f35-eb13-45637820a3f8","executionInfo":{"status":"ok","timestamp":1578463230061,"user_tz":-330,"elapsed":1636,"user":{"displayName":"Anirudh Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCdXxtVr1wLgATuZM1iQDnE6Hw_mvTb2TIVWUeUNA=s64","userId":"08894094281719011062"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["score1"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.99"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"IS-1boeig-7s","colab_type":"code","colab":{}},"source":["X_test=pd.read_csv('/content/drive/My Drive/Colab Notebooks/DigitRecognitionMnist/test.csv')\n","#X_val=pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/miteshsir/val.csv\")\n","X_train=pd.read_csv('/content/drive/My Drive/Colab Notebooks/DigitRecognitionMnist/train.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nc_8CQDThSF1","colab_type":"code","outputId":"a92143f7-1d2a-47d0-a6da-570dcadf65b5","executionInfo":{"status":"ok","timestamp":1578460756579,"user_tz":-330,"elapsed":1562,"user":{"displayName":"Anirudh Sriram","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCdXxtVr1wLgATuZM1iQDnE6Hw_mvTb2TIVWUeUNA=s64","userId":"08894094281719011062"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["mtest"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["28000"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"jLkORKUMhhRZ","colab_type":"code","colab":{}},"source":["test_id=[]\n","for i in range(mtest):\n","    test_id.append(i+1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-BpmZiGi73M","colab_type":"code","colab":{}},"source":["test_id=np.asarray(test_id)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FlUhlqnSmS9j","colab_type":"code","colab":{}},"source":["test_id=test_id.reshape(28000,)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RjM0Nmz0mfcP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}